# -*- coding: utf-8 -*-
"""test_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zl0NuwGfVAZmD4lLX2IE0NUIaoUev1Ky
"""

from linear_model.log_reg import LogisticRegression

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


from sklearn.model_selection import GridSearchCV
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

# Buat dataset sintetis
X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)

# Konversi ke DataFrame
df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])
df['target'] = y

# Tampilkan distribusi kelas target
print("\nDistribusi kelas target:")
print(df['target'].value_counts(normalize=True))

# Histogram untuk setiap fitur
for i in range(5):  # Hanya menampilkan 5 fitur pertama untuk kejelasan
    plt.subplot(1, 5, i+1)
    sns.histplot(data=df, x=f'feature_{i}', hue='target', kde=True)
    plt.title(f'Distribusi feature_{i}')

# Scatter plot untuk dua fitur pertama
plt.subplot(2, 3, 6)
sns.scatterplot(data=df, x='feature_0', y='feature_1', hue='target')
plt.title('Scatter plot: feature_0 vs feature_1')

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definisikan parameter grid
param_grid = {
    'learning_rate': [0.001, 0.01, 0.1],
    'n_iterations': [500, 1000, 1500],
    'fit_intercept': [True, False]
}

# Inisialisasi GridSearchCV
grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# Fit GridSearchCV
grid_search.fit(X_train, y_train)

# Tampilkan hasil untuk semua kombinasi parameter
results = grid_search.cv_results_
for mean_score, params in zip(results['mean_test_score'], results['params']):
    print(f"Mean cross-validation score: {mean_score:.3f} with parameters: {params}")

# Tampilkan hasil terbaik
print("Best parameters:", grid_search.best_params_)
print("Best cross-validation score:", grid_search.best_score_)

# Evaluasi model terbaik pada test set
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("\nTest set accuracy:", accuracy)

# Tampilkan laporan klasifikasi
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Fungsi untuk memprediksi dan menampilkan hasil
def predict_and_display(model, X, true_labels=None):
    # Lakukan prediksi
    predictions = model.predict(X)
    probabilities = model.predict_proba(X)

    # Tampilkan hasil
    print("\nHasil Prediksi:")
    print("Index | Prediksi | Probabilitas Kelas 0 | Probabilitas Kelas 1 | Label Sebenarnya")
    print("-" * 75)
    for i, (pred, prob) in enumerate(zip(predictions, probabilities)):
        true_label = f"| {true_labels[i]}" if true_labels is not None else ""
        print(f"{i:5d} | {pred:8d} | {prob[0]:20.4f} | {prob[1]:20.4f} {true_label}")

    if true_labels is not None:
        accuracy = accuracy_score(true_labels, predictions)
        print(f"\nAkurasi: {accuracy:.4f}")
        print("\nLaporan Klasifikasi:")
        print(classification_report(true_labels, predictions))

# Prediksi menggunakan beberapa sampel dari test set
n_samples = 10
sample_indices = np.random.choice(len(X_test), n_samples, replace=False)
X_sample = X_test[sample_indices]
y_sample = y_test[sample_indices]

print("Prediksi untuk sampel dari test set:")
predict_and_display(best_model, X_sample, y_sample)

# Buat beberapa sampel baru untuk prediksi
X_new, y_new = make_classification(n_samples=5, n_features=20, n_classes=2, random_state=42)

print("\nPrediksi untuk sampel baru:")
predict_and_display(best_model, X_new, y_new)

